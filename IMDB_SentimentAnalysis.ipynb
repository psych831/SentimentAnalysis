{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB_SentimentAnalysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQg_clhs6S39"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras import models\n",
        "from numpy import array\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlKwT5D0-sVT",
        "outputId": "2eaf7f2b-d9d2-4c7c-b798-8ed60fadc3f6"
      },
      "source": [
        "vocab_size = 10000\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words = vocab_size)\n",
        "class_names = [\"negative\", \"positive\"]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWUZBQ1d_Q-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d383e4c3-b151-4b39-96e5-b80ca33f009d"
      },
      "source": [
        "index = tf.keras.datasets.imdb.get_word_index()\n",
        "index = {k:(v+3) for k,v in index.items()}\n",
        "\n",
        "index[\"<PAD>\"]=0\n",
        "index[\"<START>\"]=0\n",
        "index[\"<UNKNOWN>\"]=0\n",
        "index[\"<UNUSED>\"]=0\n",
        "\n",
        "\n",
        "reverse_index = dict([(value, key) for (key, value) in index.items()])\n",
        "def decode_review(text):\n",
        "  return ' '.join([reverse_index.get(i, \"?\") for i in text])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvLPvFCQC3OD",
        "outputId": "bbe40666-c766-43a4-ab07-93da619ff7b3"
      },
      "source": [
        "review_length = 500\n",
        "model = models.Sequential()\n",
        "model.add(\n",
        "    layers.Embedding(\n",
        "        input_dim = vocab_size, #10000\n",
        "        output_dim = 32,\n",
        "        input_length = review_length #500\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "model.add(layers.Dropout(rate=0.25))\n",
        "model.add(layers.LSTM(units = 32))\n",
        "model.add(layers.Dropout(rate=0.25))\n",
        "model.add(layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    loss = tf.keras.losses.binary_crossentropy,\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    metrics = ['Accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 32)           320000    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 500, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 328,353\n",
            "Trainable params: 328,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxGASA_wFz3N",
        "outputId": "54d3d3f3-913c-4b3f-972c-ff34a17b4d20"
      },
      "source": [
        "review_length = 500\n",
        "\n",
        "x_train = sequence.pad_sequences(x_train, maxlen = review_length)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen = review_length)\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train, batch_size = 256,\n",
        "    epochs = 100,\n",
        "    validation_split = 0.2,\n",
        "    verbose =1\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "79/79 [==============================] - 46s 547ms/step - loss: 0.6039 - accuracy: 0.0000e+00 - val_loss: 0.4321 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "79/79 [==============================] - 43s 542ms/step - loss: 0.3477 - accuracy: 0.0000e+00 - val_loss: 0.3087 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "79/79 [==============================] - 43s 544ms/step - loss: 0.2455 - accuracy: 0.0000e+00 - val_loss: 0.2933 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "79/79 [==============================] - 43s 541ms/step - loss: 0.1937 - accuracy: 0.0000e+00 - val_loss: 0.3035 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "79/79 [==============================] - 43s 543ms/step - loss: 0.1609 - accuracy: 0.0000e+00 - val_loss: 0.3220 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "79/79 [==============================] - 43s 540ms/step - loss: 0.1362 - accuracy: 0.0000e+00 - val_loss: 0.3207 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "79/79 [==============================] - 43s 540ms/step - loss: 0.1137 - accuracy: 0.0000e+00 - val_loss: 0.3559 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "79/79 [==============================] - 43s 540ms/step - loss: 0.1028 - accuracy: 0.0000e+00 - val_loss: 0.3749 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "79/79 [==============================] - 44s 562ms/step - loss: 0.0848 - accuracy: 0.0000e+00 - val_loss: 0.3746 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "79/79 [==============================] - 43s 540ms/step - loss: 0.0704 - accuracy: 0.0000e+00 - val_loss: 0.4133 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "79/79 [==============================] - 43s 542ms/step - loss: 0.0739 - accuracy: 0.0000e+00 - val_loss: 0.4394 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "79/79 [==============================] - 43s 543ms/step - loss: 0.0610 - accuracy: 0.0000e+00 - val_loss: 0.4589 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "79/79 [==============================] - 43s 542ms/step - loss: 0.0553 - accuracy: 0.0000e+00 - val_loss: 0.4606 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "79/79 [==============================] - 43s 545ms/step - loss: 0.0608 - accuracy: 0.0000e+00 - val_loss: 0.4598 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "79/79 [==============================] - 43s 551ms/step - loss: 0.0661 - accuracy: 0.0000e+00 - val_loss: 0.4699 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "79/79 [==============================] - 43s 550ms/step - loss: 0.0472 - accuracy: 0.0000e+00 - val_loss: 0.4987 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "79/79 [==============================] - 43s 546ms/step - loss: 0.0350 - accuracy: 0.0000e+00 - val_loss: 0.5756 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "79/79 [==============================] - 43s 543ms/step - loss: 0.0319 - accuracy: 0.0000e+00 - val_loss: 0.5192 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "79/79 [==============================] - 43s 543ms/step - loss: 0.0411 - accuracy: 0.0000e+00 - val_loss: 0.5796 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "79/79 [==============================] - 43s 540ms/step - loss: 0.0366 - accuracy: 0.0000e+00 - val_loss: 0.5682 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "79/79 [==============================] - 43s 540ms/step - loss: 0.0761 - accuracy: 0.0000e+00 - val_loss: 0.5746 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "79/79 [==============================] - 43s 545ms/step - loss: 0.0383 - accuracy: 0.0000e+00 - val_loss: 0.5565 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.0346 - accuracy: 0.0000e+00 - val_loss: 0.5719 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "79/79 [==============================] - 43s 543ms/step - loss: 0.0348 - accuracy: 0.0000e+00 - val_loss: 0.6127 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "79/79 [==============================] - 43s 543ms/step - loss: 0.0320 - accuracy: 0.0000e+00 - val_loss: 0.6286 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "79/79 [==============================] - 43s 543ms/step - loss: 0.0239 - accuracy: 0.0000e+00 - val_loss: 0.6170 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "79/79 [==============================] - 43s 544ms/step - loss: 0.0183 - accuracy: 0.0000e+00 - val_loss: 0.6891 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "79/79 [==============================] - 43s 540ms/step - loss: 0.0210 - accuracy: 0.0000e+00 - val_loss: 0.6594 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "79/79 [==============================] - 43s 543ms/step - loss: 0.0179 - accuracy: 0.0000e+00 - val_loss: 0.6807 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "79/79 [==============================] - 43s 542ms/step - loss: 0.0172 - accuracy: 0.0000e+00 - val_loss: 0.8211 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "79/79 [==============================] - 43s 542ms/step - loss: 0.0231 - accuracy: 0.0000e+00 - val_loss: 0.7281 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "79/79 [==============================] - 43s 541ms/step - loss: 0.0355 - accuracy: 0.0000e+00 - val_loss: 0.6315 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "79/79 [==============================] - 43s 541ms/step - loss: 0.0242 - accuracy: 0.0000e+00 - val_loss: 0.5742 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "79/79 [==============================] - 43s 542ms/step - loss: 0.0319 - accuracy: 0.0000e+00 - val_loss: 0.6963 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "79/79 [==============================] - 43s 539ms/step - loss: 0.0227 - accuracy: 0.0000e+00 - val_loss: 0.6662 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "79/79 [==============================] - 43s 543ms/step - loss: 0.0229 - accuracy: 0.0000e+00 - val_loss: 0.6902 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "79/79 [==============================] - 43s 542ms/step - loss: 0.0162 - accuracy: 0.0000e+00 - val_loss: 0.7032 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "79/79 [==============================] - 43s 542ms/step - loss: 0.0124 - accuracy: 0.0000e+00 - val_loss: 0.7374 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "79/79 [==============================] - 42s 534ms/step - loss: 0.0381 - accuracy: 0.0000e+00 - val_loss: 0.7144 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "79/79 [==============================] - 43s 541ms/step - loss: 0.0305 - accuracy: 1.0000e-04 - val_loss: 0.6985 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "79/79 [==============================] - 43s 540ms/step - loss: 0.0182 - accuracy: 5.0000e-05 - val_loss: 0.6918 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "79/79 [==============================] - 43s 541ms/step - loss: 0.0149 - accuracy: 5.0000e-05 - val_loss: 0.6785 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "79/79 [==============================] - 43s 541ms/step - loss: 0.0147 - accuracy: 1.0000e-04 - val_loss: 0.8078 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "79/79 [==============================] - 43s 544ms/step - loss: 0.0142 - accuracy: 3.0000e-04 - val_loss: 0.7304 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "79/79 [==============================] - 43s 541ms/step - loss: 0.0695 - accuracy: 2.5000e-04 - val_loss: 0.6224 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "79/79 [==============================] - 43s 541ms/step - loss: 0.0845 - accuracy: 0.0000e+00 - val_loss: 0.5927 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "79/79 [==============================] - 43s 539ms/step - loss: 0.0173 - accuracy: 0.0000e+00 - val_loss: 0.6381 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "79/79 [==============================] - 43s 542ms/step - loss: 0.0139 - accuracy: 0.0000e+00 - val_loss: 0.6164 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "79/79 [==============================] - 43s 539ms/step - loss: 0.0128 - accuracy: 5.0000e-05 - val_loss: 0.7207 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "79/79 [==============================] - 43s 542ms/step - loss: 0.0123 - accuracy: 2.0000e-04 - val_loss: 0.7498 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "79/79 [==============================] - 43s 542ms/step - loss: 0.0224 - accuracy: 2.5000e-04 - val_loss: 0.7476 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "79/79 [==============================] - 43s 542ms/step - loss: 0.0146 - accuracy: 6.0000e-04 - val_loss: 0.7623 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "79/79 [==============================] - 43s 541ms/step - loss: 0.0142 - accuracy: 5.0000e-04 - val_loss: 0.7977 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "79/79 [==============================] - 43s 540ms/step - loss: 0.9739 - accuracy: 6.0000e-04 - val_loss: 0.6186 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "79/79 [==============================] - 43s 541ms/step - loss: 0.3983 - accuracy: 0.0000e+00 - val_loss: 0.4874 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "79/79 [==============================] - 43s 541ms/step - loss: 0.1763 - accuracy: 0.0000e+00 - val_loss: 0.4810 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "79/79 [==============================] - 43s 546ms/step - loss: 0.0943 - accuracy: 0.0000e+00 - val_loss: 0.4426 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "79/79 [==============================] - 43s 542ms/step - loss: 0.0804 - accuracy: 0.0000e+00 - val_loss: 0.4777 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "79/79 [==============================] - 43s 540ms/step - loss: 0.0625 - accuracy: 0.0000e+00 - val_loss: 0.4849 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "79/79 [==============================] - 43s 540ms/step - loss: 0.0419 - accuracy: 0.0000e+00 - val_loss: 0.5129 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "79/79 [==============================] - 43s 543ms/step - loss: 0.0427 - accuracy: 0.0000e+00 - val_loss: 0.6027 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "79/79 [==============================] - 43s 543ms/step - loss: 0.0295 - accuracy: 0.0000e+00 - val_loss: 0.5417 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "79/79 [==============================] - 43s 541ms/step - loss: 0.0246 - accuracy: 0.0000e+00 - val_loss: 0.5576 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "79/79 [==============================] - 43s 542ms/step - loss: 0.0197 - accuracy: 0.0000e+00 - val_loss: 0.5895 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "79/79 [==============================] - 43s 546ms/step - loss: 0.0182 - accuracy: 0.0000e+00 - val_loss: 0.5911 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "79/79 [==============================] - 43s 545ms/step - loss: 0.0157 - accuracy: 0.0000e+00 - val_loss: 0.6537 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "79/79 [==============================] - 43s 543ms/step - loss: 0.0146 - accuracy: 0.0000e+00 - val_loss: 0.6191 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "79/79 [==============================] - 43s 540ms/step - loss: 0.0119 - accuracy: 0.0000e+00 - val_loss: 0.6140 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "79/79 [==============================] - 42s 536ms/step - loss: 0.0139 - accuracy: 0.0000e+00 - val_loss: 0.6263 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "79/79 [==============================] - 42s 537ms/step - loss: 0.0134 - accuracy: 0.0000e+00 - val_loss: 0.6554 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "79/79 [==============================] - 43s 541ms/step - loss: 0.0099 - accuracy: 5.0000e-05 - val_loss: 0.6402 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "79/79 [==============================] - 43s 542ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.6905 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "79/79 [==============================] - 43s 540ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.7056 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "79/79 [==============================] - 43s 541ms/step - loss: 0.0108 - accuracy: 5.0000e-05 - val_loss: 0.7360 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "79/79 [==============================] - 42s 538ms/step - loss: 0.0135 - accuracy: 5.0000e-05 - val_loss: 0.6717 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "79/79 [==============================] - 43s 540ms/step - loss: 0.0883 - accuracy: 5.0000e-05 - val_loss: 0.6564 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "79/79 [==============================] - 42s 536ms/step - loss: 0.0158 - accuracy: 0.0000e+00 - val_loss: 0.6768 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "79/79 [==============================] - 42s 537ms/step - loss: 0.0117 - accuracy: 0.0000e+00 - val_loss: 0.6668 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "79/79 [==============================] - 43s 543ms/step - loss: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.7045 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "79/79 [==============================] - 43s 544ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.6985 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "79/79 [==============================] - 43s 543ms/step - loss: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.7012 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "79/79 [==============================] - 43s 547ms/step - loss: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.7142 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "79/79 [==============================] - 43s 547ms/step - loss: 0.0120 - accuracy: 5.0000e-05 - val_loss: 0.6856 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "79/79 [==============================] - 43s 545ms/step - loss: 0.0143 - accuracy: 5.0000e-05 - val_loss: 0.7821 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "79/79 [==============================] - 43s 542ms/step - loss: 0.0105 - accuracy: 1.0000e-04 - val_loss: 0.7325 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "79/79 [==============================] - 43s 542ms/step - loss: 0.0129 - accuracy: 5.0000e-05 - val_loss: 0.7312 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "79/79 [==============================] - 43s 539ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.7822 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "79/79 [==============================] - 43s 540ms/step - loss: 0.0065 - accuracy: 2.0000e-04 - val_loss: 0.7757 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "79/79 [==============================] - 43s 542ms/step - loss: 0.0121 - accuracy: 5.0000e-05 - val_loss: 0.7574 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "79/79 [==============================] - 43s 545ms/step - loss: 0.0228 - accuracy: 3.0000e-04 - val_loss: 0.7666 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "79/79 [==============================] - 43s 539ms/step - loss: 0.0138 - accuracy: 2.5000e-04 - val_loss: 0.7532 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "79/79 [==============================] - 42s 536ms/step - loss: 0.0079 - accuracy: 2.0000e-04 - val_loss: 0.7639 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "79/79 [==============================] - 42s 538ms/step - loss: 0.0115 - accuracy: 1.5000e-04 - val_loss: 0.8344 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "79/79 [==============================] - 43s 539ms/step - loss: 0.0134 - accuracy: 2.0000e-04 - val_loss: 0.7250 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "79/79 [==============================] - 43s 539ms/step - loss: 0.0104 - accuracy: 3.0000e-04 - val_loss: 0.7129 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "79/79 [==============================] - 42s 537ms/step - loss: 0.0320 - accuracy: 5.5000e-04 - val_loss: 0.8407 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "79/79 [==============================] - 42s 536ms/step - loss: 0.0463 - accuracy: 2.5000e-04 - val_loss: 0.6776 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "79/79 [==============================] - 43s 539ms/step - loss: 0.0108 - accuracy: 2.0000e-04 - val_loss: 0.7063 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "79/79 [==============================] - 43s 541ms/step - loss: 0.0195 - accuracy: 2.0000e-04 - val_loss: 0.7369 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "79/79 [==============================] - 42s 538ms/step - loss: 0.0105 - accuracy: 3.5000e-04 - val_loss: 0.7278 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74rF6A1IGuX-",
        "outputId": "335cc6de-98ce-446b-e8b9-01a8065889f7"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "predicted_classes = model.predict_classes(x_test)\n",
        "print(classification_report(y_test, predicted_classes, target_names=class_names))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.83      0.86      0.85     12500\n",
            "    positive       0.86      0.83      0.84     12500\n",
            "\n",
            "    accuracy                           0.84     25000\n",
            "   macro avg       0.84      0.84      0.84     25000\n",
            "weighted avg       0.84      0.84      0.84     25000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQyQBRiZHRDr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c99142f-0fc9-4d80-e649-40e4a590bc05"
      },
      "source": [
        "# Our Review\n",
        "\n",
        "\n",
        "Review = \"This is a very good comedy movie\"\n",
        "\n",
        "review=Review.lower()\n",
        "\n",
        "tmp = []\n",
        "for word in review.split(\" \"):\n",
        "  tmp.append(index[word])\n",
        "\n",
        "tmp_padded = sequence.pad_sequences([tmp], maxlen=review_length)\n",
        "\n",
        "rawprediction = model.predict(array([tmp_padded][0]))[0][0]\n",
        "prediction = int(round(rawprediction))\n",
        "\n",
        "print(\"Review: \" + review)\n",
        "print(\"Raw Prediction: \" + str(rawprediction))\n",
        "print(\"Predicted Class: \" + class_names[prediction])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: this is a very good comedy movie\n",
            "Raw Prediction: 0.9155137\n",
            "Predicted Class: positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykD1TeWXG5Zx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}